{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"spotify_CNN_RNN.ipynb","provenance":[],"authorship_tag":"ABX9TyP5qIBMm4PXO9kEPChQID4R"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"gLxoIUkCTgs3","colab_type":"code","colab":{}},"source":["!pip install wandb\n","!pip install category_encoders"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iAOiOk-4TtEb","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, LSTM\n","from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n","import wandb\n","from wandb.keras import WandbCallback\n","from category_encoders import TargetEncoder\n","from category_encoders import OrdinalEncoder\n","from tensorflow import keras\n","\n","songs = pd.read_csv('http://www.zernach.com/wp-content/uploads/2020/02/SpotifyAudioFeaturesApril2019.csv')\n","songs['track_index_num'] = songs.index\n","print(songs.shape)\n","songs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gG5mtB7cTvrK","colab_type":"code","colab":{}},"source":["target = 'track_index_num'\n","features = songs100.drop(columns=[target, 'artist_name', 'track_name', 'track_id', 'album_cover_url']).columns\n","\n","#train, test = train_test_split(songs, train_size=0.01, test_size=0.99, random_state=42)\n","\n","x_train = songs100[features]\n","y_train = songs100[target]\n","#x_test = test[features]\n","#y_test = test[target]\n","\n","#encoder = OrdinalEncoder()\n","#encoder.fit(x_train, y_train)\n","#x_train_encoded = encoder.transform(x_train)\n","#x_test_encoded = encoder.transform(x_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RfZx9NupT-J5","colab_type":"code","colab":{}},"source":["seed = 7\n","numpy.random.seed(seed)\n","\n","# Important Hyperparameters\n","batch_size = 100\n","epochs = 1\n","optimizer = 'adam'\n","\n","model = Sequential()\n","\n","# Input => Hidden\n","model.add(Dense(14, input_dim=14, activation='sigmoid'))\n","# Hidden\n","model.add(Dense(28, activation='sigmoid'))\n","# Hidden\n","model.add(Dense(56, activation='sigmoid'))\n","# Hidden\n","model.add(Dense(112, activation='sigmoid'))\n","# Hidden\n","model.add(Dense(224, activation='sigmoid'))\n","# Hidden\n","model.add(Dense(448, activation='sigmoid'))\n","# Hidden\n","model.add(Dense(1000, activation='sigmoid'))\n","# Output\n","model.add(Dense(130663,activation='sigmoid'))\n","\n","#Compile\n","model.compile(loss='sparse_categorical_crossentropy',\n","                    optimizer=optimizer,\n","                    metrics=['accuracy'])\n","\n","history = model.fit(x_train, y_train, \n","                    #validation_data=(x_test_encoded,y_test), \n","                    epochs=epochs,\n","                    batch_size=batch_size,\n","                    #verbose=True\n","                    )\n","\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dzQcoN9CT-ud","colab_type":"code","colab":{}},"source":["\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from keras.utils import np_utils\n","from keras.models import Model, Sequential\n","from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n","from keras.optimizers import RMSprop\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing import sequence\n","from keras.callbacks import EarlyStopping\n","from keras import layers"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_wwCTqssUCqD","colab_type":"code","colab":{}},"source":["# need that csv\n","lyricsdataframe=pd.read_csv('./finallyrics1.csv',error_bad_lines=False)\n","lyricsdataframe"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x_oI1JlpUOrD","colab_type":"code","colab":{}},"source":["\n","X=lyricsdataframe['Lyrics']\n","X"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RZByK0ZAUQry","colab_type":"code","colab":{}},"source":["Y=lyricsdataframe['Mood']\n","Y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vqsyMAHTUT31","colab_type":"code","colab":{}},"source":[":\n","laen=LabelEncoder()\n","y=laen.fit_transform(Y)\n","y=np_utils.to_categorical(y)\n","y\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0l9jdeSYUV-1","colab_type":"code","colab":{}},"source":["X_train,X_test,Y_train,Y_test=train_test_split(X,y,test_size=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LSwdJgnqUYAh","colab_type":"code","colab":{}},"source":["def tokkk(x,max_w,max_l):\n","    lyricstok = Tokenizer(num_words=max_w)\n","    lyricstok.fit_on_texts(x)\n","    seque = lyricstok.texts_to_sequences(x)\n","    sequen_matrix = sequence.pad_sequences(seque,maxlen=max_l)\n","    return sequen_matrix"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jdDdKuGdUamb","colab_type":"code","colab":{}},"source":["sequences_matrix = tokkk(X_train,550,600)\n","sequences_matrix.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D32xqMTxUeiB","colab_type":"code","colab":{}},"source":["2]:\n","max_words = 550\n","max_len = 600"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZrzqJaakUho4","colab_type":"code","colab":{}},"source":["inp = Input(name='inputs',shape=[max_len])\n","i = Embedding(max_words,50,input_length=max_len)(inp)\n","i = LSTM(32)(i)\n","i = Dense(256, name='FC1')(i)\n","i = Activation('relu')(i)\n","i = Dropout(0.2)(i)\n","i = Dense(4,name='out_layer')(i)\n","out = Activation('softmax')(i)\n","model = Model(inputs=inp,outputs=out)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xTV3ft-nUiIU","colab_type":"code","colab":{}},"source":["\n","model.compile(loss='categorical_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P9aasF-BUmx9","colab_type":"code","colab":{}},"source":["history=model.fit(sequences_matrix,Y_train,batch_size=128,epochs=5,validation_split=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dGUmgXiOUprG","colab_type":"code","colab":{}},"source":["\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'], loc='upper left')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wiN9V1nyVAFz","colab_type":"code","colab":{}},"source":["import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout,Activation,Flatten\n","from keras.optimizers import Adam\n","import numpy as np\n","\n","\n","basedir='/Users/achyutajha/Documents/PSU Study Mat/Fall-II/Deep Learning/Project/Data/KaggleData/fer2013/'\n","training_path = basedir + 'Training'\n","testing_path = basedir + 'PublicTest'\n","num_classes = 7\n","\n","################## Data Collection and preprocessing stages ##################\n","\n","def img_to_matrix(imagePath):\n","    image=cv2.imread(imagePath)\n","    image=cv2.resize(image, (48,48))\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    return gray\n","\n","\n","def prepare_data(path):\n","    X=[]\n","    Y=[]\n","    labels = []\n","    for (_, dirnames, _) in walk(path):\n","        labels.extend(dirnames)\n","    for label in labels:\n","        for root, dirs, files in os.walk(os.path.abspath(path+'/'+label)):\n","            for file in files:\n","                imagePath=root +'/'+ file\n","                image=img_to_matrix(imagePath)\n","                X.append(image)\n","                Y.append([int(label)])\n","    return X,Y\n","\n","\n","def preprocess(X,Y):\n","    flat_X = np.array(X)\n","    flat_Y = np.array(Y)\n","    flat_X = flat_X.astype('float32')\n","    flat_X/=255\n","    flat_Y = keras.utils.to_categorical(flat_Y, num_classes)\n","    return flat_X,flat_Y\n","\n","\n","X_train,Y_train = prepare_data(training_path)\n","X_test,Y_test = prepare_data(testing_path)\n","\n","\n","flat_X_train,flat_Y_train = preprocess(X_train,Y_train)\n","flat_X_test,flat_Y_test = preprocess(X_test,Y_test)\n","\n","\n","flat_X_train = flat_X_train.reshape(flat_X_train.shape[0], 48, 48, 1)\n","flat_X_test = flat_X_test.reshape(flat_X_test.shape[0], 48, 48, 1)\n","\n","\n","\n","from keras import regularizers\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.layers.normalization import BatchNormalization\n","\n","\n","\n","################### Build the neural network ##################\n","\n","model_8 = Sequential()\n","\n","#1st block\n","model_8.add(Conv2D(64, (3,3), strides = (1,1), padding='same',\n","                 input_shape = flat_X_train.shape[1:],\n","                   kernel_initializer=\"lecun_uniform\",\n","                   kernel_regularizer=regularizers.l2(0)))\n","model_8.add(BatchNormalization())\n","model_8.add(Activation('tanh'))\n","model_8.add(MaxPooling2D(pool_size=(2, 2)))\n","model_8.add(Dropout(0.25))\n","\n","#2nd block\n","model_8.add(Conv2D(128, (5,5), strides = (1,1),kernel_regularizer=regularizers.l2(0)))\n","model_8.add(BatchNormalization())\n","model_8.add(Activation('tanh'))\n","model_8.add(MaxPooling2D(pool_size=(2, 2)))\n","model_8.add(Dropout(0.25))\n","\n","\n","#3rd block\n","model_8.add(Conv2D(512, (3,3), strides = (1,1), padding='same',kernel_regularizer=regularizers.l2(0)))\n","model_8.add(BatchNormalization())\n","model_8.add(Activation('tanh'))\n","model_8.add(MaxPooling2D(pool_size=(2, 2)))\n","model_8.add(Dropout(0.5))\n","\n","#4th block\n","model_8.add(Conv2D(512, (3,3), strides = (1,1), padding='same',kernel_regularizer=regularizers.l2(0)))\n","model_8.add(BatchNormalization())\n","model_8.add(Activation('tanh'))\n","model_8.add(MaxPooling2D(pool_size=(2, 2)))\n","model_8.add(Dropout(0.1))\n","\n","\n","#5th block\n","model_8.add(Flatten())\n","model_8.add(Dense(256,kernel_initializer=\"lecun_uniform\"))\n","model_8.add(BatchNormalization())\n","model_8.add(Activation('relu'))\n","model_8.add(Dropout(0.5))\n","model_8.add(Dense(512,kernel_initializer=\"lecun_uniform\"))\n","model_8.add(BatchNormalization())\n","model_8.add(Activation('relu'))\n","model_8.add(Dropout(0.5))\n","model_8.add(Dense(num_classes))\n","model_8.add(Activation('softmax'))\n","\n","model_8.summary()\n","\n","\n","learning_rate = .001\n","# sgd = SGD(lr=learning_rate, decay=1e-6, momentum=0.9, nesterov=True)\n","\n","model_8.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=Adam(lr=learning_rate),\n","              metrics=['accuracy'])\n","\n","\n","from keras.callbacks import EarlyStopping\n","earlystop = EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=7, \\\n","                          verbose=1, mode='auto')\n","callbacks = [earlystop]\n","\n","\n","batch_size = 128\n","epochs = 35\n","history_8 = model_8.fit(\n","    flat_X_train, flat_Y_train,\n","    batch_size=batch_size,\n","    epochs=epochs,\n","    verbose=1,\n","    callbacks=callbacks,\n","    validation_data=(flat_X_test,flat_Y_test))\n","\n","\n","model_8.save('./face_cnn_model.h5')"],"execution_count":0,"outputs":[]}]}